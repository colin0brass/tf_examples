{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c915535b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ===========================================\n",
    "# == Training image classification network ==\n",
    "# ===========================================\n",
    "\n",
    "# https://www.tensorflow.org/lite/tutorials/model_maker_image_classification\n",
    "# with incremental changes\n",
    "\n",
    "# some ideas here for customising to use checkpoints:\n",
    "# https://stackoverflow.com/questions/69444878/how-to-continue-training-with-checkpoints-using-object-detector-efficientdetlite\n",
    "\n",
    "# available model_specs:\n",
    "# https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/core/task/model_spec/image_spec.py#L29-L59\n",
    "\n",
    "# Ensure the kernel is selected from virtual environment\n",
    "\n",
    "# note, if getting error message, suspect temp folder tidied away, so delete and try again\n",
    "# OSError: SavedModel file does not exist at: /var/folders/bt/pk67cdmj12l8t7d5zbkx4hbr0000gn/T/tfhub_modules\n",
    "        \n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "# Extracted functions to enable continued training; copied from:\n",
    "# https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/core/task/image_classifier.py\n",
    "# https://github.com/tensorflow/examples/blob/master/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py\n",
    "from tensorflow_examples.lite.model_maker.core.task import model_util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "\n",
    "import itertools\n",
    "import sys\n",
    "import pathlib\n",
    "import shutil\n",
    "import re\n",
    "import io\n",
    "import time\n",
    "\n",
    "import PIL\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "print(\"TF version:\", tf.__version__)\n",
    "\n",
    "# # Apple feature to optimise performance using ML compute resources in Mac\n",
    "# try:\n",
    "#     from tensorflow.python.compiler.mlcompute import mlcompute\n",
    "#     mlcompute.set_mlc_device(device_name='any')\n",
    "#     print('Using Apple MLCompute')\n",
    "# except:\n",
    "#     print('Apple MLCompute not found')\n",
    "#     pass\n",
    "\n",
    "tf.get_logger().setLevel('ERROR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76804cab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training configuration\n",
    "TRAINING_EPOCHS = 2\n",
    "EXPORT_MODEL    = True\n",
    "RUN_TRAINING    = True\n",
    "RUN_TEST        = True\n",
    "NUM_TEST_IMAGES = 2\n",
    "\n",
    "# Model selection\n",
    "# options look to be:\n",
    "# mobilenet_v2, resnet_50, efficientnet_lite0, efficientnet_lite1, efficientnet_lite2, efficientnet_lite3, efficientnet_lite4\n",
    "# the larger versions of efficientnet look to be for inputs larger than 224x224\n",
    "\n",
    "PROCESS_LIST_OF_MODELS = True\n",
    "if not PROCESS_LIST_OF_MODELS:\n",
    "    MODEL_SPEC_NAME = 'efficientnet_lite1'\n",
    "else:\n",
    "    ALL_MODELS = ['mobilenet_v2', 'resnet_50', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4']\n",
    "    FEW_MODELS = ['mobilenet_v2', 'efficientnet_lite0', 'efficientnet_lite4']\n",
    "    TWO_MODELS = ['mobilenet_v2', 'efficientnet_lite0']\n",
    "    ONE_MODEL  = ['efficientnet_lite0']\n",
    "    \n",
    "    MODEL_LIST = ALL_MODELS\n",
    "\n",
    "OUTPUT_DIR='.'\n",
    "LABEL_FILENAME = 'labels.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e99ebba0",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = tf.keras.utils.get_file('flower_photos',\n",
    "'https://storage.googleapis.com/download.tensorflow.org/example_images/flower_photos.tgz', untar=True)\n",
    "\n",
    "data = DataLoader.from_folder(image_path)\n",
    "train_data, rest_data = data.split(0.8)\n",
    "validation_data, test_data = rest_data.split(0.5)\n",
    "\n",
    "print(\"Show a few example images\")\n",
    "plt.figure(figsize=(10,10))\n",
    "for i, (image, label) in enumerate(data.gen_dataset().unbatch().take(25)):\n",
    "  plt.subplot(5,5,i+1)\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "  plt.grid(False)\n",
    "  plt.imshow(image.numpy(), cmap=plt.cm.gray)\n",
    "  plt.xlabel(data.index_to_label[label.numpy()])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98c40de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(model_spec_name, epochs_between_evals, validation_data, do_data_augmentation, do_train=False):\n",
    "    model = image_classifier.create(train_data,\n",
    "                                    model_spec=model_spec.get(model_spec_name),\n",
    "                                    epochs=epochs_between_evals,\n",
    "                                    validation_data=validation_data,\n",
    "                                    use_augmentation=do_data_augmentation,\n",
    "                                    do_train=do_train)\n",
    "    return model\n",
    "    \n",
    "def prepare_model_for_training(model, train_data, validation_data=None, hparams=None, steps_per_epoch=None):\n",
    "    hparams = model._get_hparams_or_default(hparams)\n",
    "    \n",
    "#     model.create_model() # already done in build_model()\n",
    "\n",
    "    train_ds = train_data.gen_dataset(\n",
    "                                hparams.batch_size,\n",
    "                                is_training=True,\n",
    "                                shuffle=model.shuffle,\n",
    "                                preprocess=model.preprocess)\n",
    "    \n",
    "    steps_per_epoch = model_util.get_steps_per_epoch(steps_per_epoch,\n",
    "                                                     hparams.batch_size,\n",
    "                                                     train_data)\n",
    "    if steps_per_epoch is not None:\n",
    "        train_ds = train_ds.take(steps_per_epoch)\n",
    "        \n",
    "    validation_ds = None\n",
    "    if validation_data is not None:\n",
    "        validation_ds = validation_data.gen_dataset(\n",
    "            hparams.batch_size, is_training=False, preprocess=model.preprocess)\n",
    "\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(\n",
    "        label_smoothing=hparams.label_smoothing)\n",
    "\n",
    "    # Compile the model\n",
    "    model.model.compile(\n",
    "        optimizer=tf.keras.optimizers.SGD(\n",
    "            lr=hparams.learning_rate, momentum=hparams.momentum),\n",
    "        loss=loss,\n",
    "        metrics=[\"accuracy\"])\n",
    "\n",
    "\n",
    "    return train_ds, validation_ds\n",
    "\n",
    "def model_train_local(model, train_ds, validation_ds=None, hparams=None, steps_per_epoch=None):\n",
    "    hparams = model._get_hparams_or_default(hparams)\n",
    "    \n",
    "    model.history = model.model.fit(\n",
    "      train_ds,\n",
    "      epochs=hparams.train_epochs,\n",
    "      steps_per_epoch=steps_per_epoch,\n",
    "      validation_data=validation_ds)\n",
    "    \n",
    "def train_model(model, total_training_epochs, epochs_between_evals, steps_per_epoch=None,\n",
    "                train_ds=None, validation_ds=None):\n",
    "    num_training_loops = int(total_training_epochs / epochs_between_evals)\n",
    "\n",
    "    history = {'loss':[], 'accuracy':[], 'val_loss':[], 'val_accuracy':[]}\n",
    "    for loop in range(num_training_loops):\n",
    "        print(\"Loop: {} of {}\".format(loop+1, num_training_loops))\n",
    "\n",
    "        model_train_local(model, train_ds, validation_ds=validation_ds, hparams=None, steps_per_epoch=steps_per_epoch)\n",
    "        hist = model.history.history # model, history call-back, history property\n",
    "\n",
    "        history['loss'].append(hist['loss'][-1]) # add last element from list\n",
    "        history['accuracy'].append(hist['accuracy'][-1]) # add last element from list\n",
    "#         print(\"loss=\", hist['loss'][-1], \"; accuracy=\", hist['accuracy'][-1])\n",
    "\n",
    "        val_loss, val_accuracy = model.evaluate(test_data)\n",
    "#         print(\"val_loss=\", val_loss, \"; val_accuracy=\", val_accuracy)\n",
    "\n",
    "        history['val_loss'].append(round(val_loss, 2))\n",
    "        history['val_accuracy'].append(round(val_accuracy, 2))\n",
    "\n",
    "    return history\n",
    "\n",
    "def plot_training_metrics(model_name, hist, width=16, height=4):\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.subplots_adjust(hspace=0.7)\n",
    "\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.plot(hist[\"loss\"], label='Training loss')\n",
    "    plt.plot(hist[\"val_loss\"], label='Validation loss')\n",
    "    y_max = max(max(hist[\"loss\"]), max(hist[\"val_loss\"]))\n",
    "    plt.ylim([0,y_max])\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.legend(loc='upper right')\n",
    "    plt.title('Loss')\n",
    "\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xlabel(\"Training Steps\")\n",
    "    plt.plot(hist[\"accuracy\"], label='Training accuracy')\n",
    "    plt.plot(hist[\"val_accuracy\"], label='Validation accuracy')\n",
    "    plt.ylim([0,1])\n",
    "    plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "    plt.legend(loc='lower right')\n",
    "    plt.title('Accuracy')\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "def export_tflite(model, output_dir, model_filename, labels_filename):\n",
    "    model.export(export_dir=output_dir,\n",
    "                 tflite_filename=model_filename,\n",
    "                 label_filename=labels_filename,\n",
    "                 export_format=[ExportFormat.TFLITE, ExportFormat.LABEL])\n",
    "\n",
    "def load_tflite_model_and_labels(model_file, labels_file):\n",
    "    # Read TensorFlow Lite model from TensorFlow Lite file.\n",
    "    with tf.io.gfile.GFile(model_file, 'rb') as f:\n",
    "        model_content = f.read()\n",
    "\n",
    "    # Read label names from label file.\n",
    "    with tf.io.gfile.GFile(labels_file, 'r') as f:\n",
    "        label_names = f.read().split('\\n')\n",
    "\n",
    "    # Initialze TensorFlow Lite inpterpreter.\n",
    "    interpreter = tf.lite.Interpreter(model_content=model_content)\n",
    "\n",
    "    return interpreter, label_names\n",
    "\n",
    "def input_preprocess(image, model_input_details=None, mean_rgb=0.0, stddev_rgb=255.0):\n",
    "    floating_model = model_input_details['dtype'] == np.float32\n",
    "    batch, height, width, channels = model_input_details['shape']\n",
    "    input_image_shape = [height, width]\n",
    "\n",
    "    image = tf.compat.v1.image.resize(image, input_image_shape)\n",
    "\n",
    "    if floating_model:\n",
    "        image = tf.cast(image, tf.float32)\n",
    "        image -= tf.constant(mean_rgb, shape=[1, 1, 3], dtype=image.dtype)\n",
    "        image /= tf.constant(stddev_rgb, shape=[1, 1, 3], dtype=image.dtype)\n",
    "    else:\n",
    "        image = tf.cast(image, tf.uint8)\n",
    "            \n",
    "    return image\n",
    "\n",
    "def test_model(model, interpreter, test_data, label_names, num_test_images=1, inf_time_ms_list=[]):\n",
    "    print('Number of test images =', test_data.size)\n",
    "    if num_test_images is None:\n",
    "        num_test_images=test_data.size\n",
    "    else:\n",
    "        print(\"Limiting to:\", num_test_images, \" for test\")\n",
    "\n",
    "    model_input_details = interpreter.get_input_details()[0]\n",
    "    interpreter.allocate_tensors()\n",
    "    input_index = interpreter.get_input_details()[0]['index']\n",
    "    output = interpreter.tensor(interpreter.get_output_details()[0][\"index\"])\n",
    "    \n",
    "    # check the type of the input tensor\n",
    "    floating_model = interpreter.get_input_details()[0]['dtype'] == np.float32\n",
    "\n",
    "    # Run predictions on each test image data and calculate accuracy.\n",
    "    accurate_count = 0\n",
    "    total_count = 0\n",
    "    for i, (image, label) in enumerate(test_data.gen_dataset().unbatch().take(num_test_images)):\n",
    "        # Pre-process input image\n",
    "        image = input_preprocess(image, model_input_details=model_input_details)\n",
    "        input_data = np.expand_dims(image, axis=0) # add batch dimension\n",
    "\n",
    "        # Run inference (with timing)\n",
    "        interpreter.set_tensor(input_index, input_data)\n",
    "        start_time = time.time()\n",
    "        interpreter.invoke()\n",
    "        finish_time = time.time()\n",
    "        inference_time_ms = int((finish_time - start_time)*1000)\n",
    "        inf_time_ms_list.append(inference_time_ms)\n",
    "\n",
    "        # Post-processing: remove batch dimension and find the label with highest probability.\n",
    "        predict_label = np.argmax(output()[0])\n",
    "        # Get label name with label index.\n",
    "        predict_label_name = label_names[predict_label]\n",
    "        prediction_is_correct = (predict_label == label.numpy())\n",
    "        if prediction_is_correct:\n",
    "            format_string = '{:d}: Correct prediction ({:s} == {:s})'\n",
    "        else:\n",
    "            format_string = '{:d}: Incorrect: predicted {:s} but should have been {:s}'\n",
    "        print(format_string.format(i+1, predict_label_name, data.index_to_label[label.numpy()]))\n",
    "\n",
    "        accurate_count += prediction_is_correct\n",
    "        total_count += 1\n",
    "\n",
    "    accuracy = accurate_count * 1.0 / total_count\n",
    "    print('TensorFlow Lite model accuracy = {:.1f}%'.format(accuracy*100))\n",
    "    print('Inference time (ms): min={:,.0f}, mean={:,.0f}, max={:,.0f}'.format(min(inf_time_ms_list), np.mean(inf_time_ms_list), max(inf_time_ms_list)))\n",
    "\n",
    "def build_and_train(model_spec_name='efficientnet_lite0',\n",
    "                    run_training=True,\n",
    "                    total_training_epochs=1, epochs_between_evals=1,\n",
    "                    validation_data=None,\n",
    "                    test_data=None,\n",
    "                    export_model=False, output_dir='.',\n",
    "                    run_test=True, num_test_images=None):\n",
    "    \n",
    "    print('\\nBuild model:', model_spec_name)\n",
    "    model = build_model(model_spec_name,\n",
    "                        epochs_between_evals=epochs_between_evals,\n",
    "                        validation_data=validation_data,\n",
    "                        do_data_augmentation=True,\n",
    "                        do_train=False)\n",
    "    \n",
    "    print('Model input shape:', model.model_spec.input_image_shape)\n",
    "    \n",
    "    val_accuracy = None\n",
    "    history      = None\n",
    "    if run_training:\n",
    "        print('\\nPrepare model for retraining')\n",
    "        train_ds, validation_ds = prepare_model_for_training(model, train_data, validation_data=validation_data, hparams=None, steps_per_epoch=None)\n",
    "\n",
    "        print('\\nTrain model:')\n",
    "        history = train_model(model, total_training_epochs, epochs_between_evals, steps_per_epoch=None,\n",
    "                              train_ds=train_ds, validation_ds=validation_ds)\n",
    "\n",
    "        print('\\nTraining Metrics:')\n",
    "        plot_training_metrics(model_spec_name, history)\n",
    "\n",
    "        train_accuracy = float(history['accuracy'][-1])\n",
    "        val_accuracy   = float(history['val_accuracy'][-1])\n",
    "        train_loss     = float(history['loss'][-1])\n",
    "        val_loss       = float(history['val_loss'][-1])\n",
    "        print('Training:     accuracy={0:.2f}'.format(train_accuracy)+'; loss={0:.2f}'.format(train_loss))\n",
    "        print('Verification: accuracy={0:.2f}'.format(val_accuracy)+'; loss={0:.2f}'.format(val_loss))\n",
    "        val_accuracy   = round(val_accuracy, 2)\n",
    "    \n",
    "    file_size_mb = None\n",
    "    model_filename = model_spec_name+'.tflite'\n",
    "    model_file  = os.path.join(output_dir, model_filename)\n",
    "    labels_file = os.path.join(output_dir, LABEL_FILENAME)\n",
    "    if run_training and export_model:\n",
    "        print('\\nExport model file:')\n",
    "        export_tflite(model=model,\n",
    "                      output_dir=output_dir,\n",
    "                      model_filename=model_filename,\n",
    "                      labels_filename=LABEL_FILENAME)\n",
    "        if os.path.isfile(model_file):\n",
    "            file_size_mb = round(os.stat(model_file).st_size / 1024 / 1024, 2)\n",
    "\n",
    "    inf_time_ms_list=[]\n",
    "    average_inf_time_ms=None\n",
    "    if run_test:\n",
    "        print('\\nTest model file:')\n",
    "        interpreter, label_names = load_tflite_model_and_labels(model_file, labels_file)\n",
    "        test_model(model, interpreter, test_data, label_names, num_test_images=num_test_images, inf_time_ms_list=inf_time_ms_list)\n",
    "        average_inf_time_ms = round(np.mean(inf_time_ms_list), 2)\n",
    "    \n",
    "    model_metrics = {'model_spec_name':model_spec_name,\n",
    "                 'history':history,\n",
    "                 'val_accuracy':val_accuracy,\n",
    "                 'model_size_mb':file_size_mb,\n",
    "                 'inference_time_ms':average_inf_time_ms}\n",
    "\n",
    "    return model_metrics\n",
    "\n",
    "def display_model_metrics_summary(model_metrics):\n",
    "    metrics = model_metrics.copy()\n",
    "    metrics.pop('history')\n",
    "\n",
    "    print(\"{:<20} {:<10}\".format('Key', 'Value'))\n",
    "    for k, v in metrics.items():\n",
    "        print(\"{!s:<20} {!s:<10}\".format(k, v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba20c5d7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## =========================== ##\n",
    "## Build, Train and Test Model ##\n",
    "## =========================== ##\n",
    "if PROCESS_LIST_OF_MODELS:\n",
    "    print('Not configured for single model; continuing to list of models')\n",
    "else:\n",
    "    model_metrics = build_and_train(model_spec_name=MODEL_SPEC_NAME,\n",
    "                                    run_training=RUN_TRAINING,\n",
    "                                    total_training_epochs=TRAINING_EPOCHS,\n",
    "                                    validation_data=validation_data,\n",
    "                                    test_data=test_data,\n",
    "                                    export_model=EXPORT_MODEL,\n",
    "                                    output_dir=OUTPUT_DIR,\n",
    "                                    run_test=RUN_TEST,\n",
    "                                    num_test_images=NUM_TEST_IMAGES)\n",
    "\n",
    "    display_model_metrics_summary(model_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "888b60dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_metrics_list(model_metrics_list, width=16, height=4):\n",
    "    fig = plt.figure(figsize=(width, height))\n",
    "    fig.subplots_adjust(hspace=0.7)\n",
    "\n",
    "    for model_metrics in model_metrics_list:\n",
    "        model_name = model_metrics.get('model_spec_name','')\n",
    "        hist = model_metrics.get('history',{})\n",
    "        \n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylim([0,1])\n",
    "        plt.plot(hist[\"accuracy\"], label=model_name)\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Training Accuracy')\n",
    "\n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.ylabel(\"Accuracy\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.ylim([0,1])\n",
    "        plt.plot(hist[\"val_accuracy\"], label=model_name)\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.title('Validation Accuracy')\n",
    "\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        plt.plot(hist[\"loss\"], label=model_name)\n",
    "        y_max = max(max(hist[\"loss\"]), max(hist[\"val_loss\"]))\n",
    "        plt.ylim([0,y_max])\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Training Loss')\n",
    "\n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.ylabel(\"Loss\")\n",
    "        plt.xlabel(\"Training Steps\")\n",
    "        y_max = max(max(hist[\"loss\"]), max(hist[\"val_loss\"]))\n",
    "        plt.ylim([0,y_max])\n",
    "        plt.plot(hist[\"val_loss\"], label=model_name)\n",
    "        plt.gca().xaxis.set_major_locator(MaxNLocator(integer=True))\n",
    "        plt.legend(loc='upper right')\n",
    "        plt.title('Validation Loss')\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "def display_model_metrics_list_summary(model_metrics_list):\n",
    "    df = pd.DataFrame(model_metrics_list)\n",
    "    df = df.drop(['history'], axis='columns')\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "def build_and_train_model_list(model_list=['efficientnet_lite0'],\n",
    "                               run_training=True,\n",
    "                               total_training_epochs=1, epochs_between_evals=1,\n",
    "                               validation_data=None,\n",
    "                               test_data=None,\n",
    "                               export_model=False, output_dir='.',\n",
    "                               run_test=True, num_test_images=None):\n",
    "\n",
    "    print('Model list:', model_list)\n",
    "    model_metrics_list = []\n",
    "    for model_spec_name in MODEL_LIST:\n",
    "        \n",
    "        print('\\nBuild model:', model_spec_name)\n",
    "        model = build_model(model_spec_name,\n",
    "                            epochs_between_evals=epochs_between_evals,\n",
    "                            validation_data=validation_data,\n",
    "                            do_data_augmentation=True,\n",
    "                            do_train=False)\n",
    "\n",
    "        print('Model input shape:', model.model_spec.input_image_shape)\n",
    "\n",
    "        val_accuracy = None\n",
    "        history      = None\n",
    "        if run_training:\n",
    "            print('\\nPrepare model for retraining')\n",
    "            train_ds, validation_ds = prepare_model_for_training(model, train_data, validation_data=validation_data, hparams=None, steps_per_epoch=None)\n",
    "\n",
    "            print('\\nTrain model:')\n",
    "            history = train_model(model, total_training_epochs, epochs_between_evals, steps_per_epoch=None,\n",
    "                                  train_ds=train_ds, validation_ds=validation_ds)\n",
    "\n",
    "            print('\\nTraining Metrics:')\n",
    "            plot_training_metrics(model_spec_name, history)\n",
    "\n",
    "            train_accuracy = float(history['accuracy'][-1])\n",
    "            val_accuracy   = float(history['val_accuracy'][-1])\n",
    "            train_loss     = float(history['loss'][-1])\n",
    "            val_loss       = float(history['val_loss'][-1])\n",
    "            print('Training:     accuracy={0:.2f}'.format(train_accuracy)+'; loss={0:.2f}'.format(train_loss))\n",
    "            print('Verification: accuracy={0:.2f}'.format(val_accuracy)+'; loss={0:.2f}'.format(val_loss))\n",
    "            val_accuracy   = round(val_accuracy, 2)\n",
    "\n",
    "        file_size_mb = None\n",
    "        model_filename = model_spec_name+'.tflite'\n",
    "        model_file  = os.path.join(output_dir, model_filename)\n",
    "        labels_file = os.path.join(output_dir, LABEL_FILENAME)\n",
    "        if run_training and export_model:\n",
    "            print('\\nExport model file:')\n",
    "            export_tflite(model=model,\n",
    "                          output_dir=output_dir,\n",
    "                          model_filename=model_filename,\n",
    "                          labels_filename=LABEL_FILENAME)\n",
    "            model_file = os.path.join(output_dir, model_filename)\n",
    "            if os.path.isfile(model_file):\n",
    "                file_size_mb = round(os.stat(model_file).st_size / 1024 / 1024, 2)\n",
    "\n",
    "        inf_time_ms_list=[]\n",
    "        average_inf_time_ms=None\n",
    "        if run_test:\n",
    "            print('\\nTest model file:')\n",
    "            interpreter, label_names = load_tflite_model_and_labels(model_file, labels_file)\n",
    "            test_model(model, interpreter, test_data, label_names, num_test_images=num_test_images, inf_time_ms_list=inf_time_ms_list)\n",
    "            average_inf_time_ms = round(np.mean(inf_time_ms_list), 2)\n",
    "\n",
    "        model_metrics = {'model_spec_name':model_spec_name,\n",
    "                     'history':history,\n",
    "                     'val_accuracy':val_accuracy,\n",
    "                     'model_size_mb':file_size_mb,\n",
    "                     'inference_time_ms':average_inf_time_ms}\n",
    "\n",
    "        model_metrics_list.append(model_metrics)\n",
    "    \n",
    "    print('\\nTraining History')\n",
    "    plot_training_metrics_list(model_metrics_list)\n",
    "    \n",
    "    print('\\nSummary Metrics')\n",
    "    df = display_model_metrics_list_summary(model_metrics_list)\n",
    "\n",
    "    return model_metrics_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2d2a9e6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## =========================== ##\n",
    "## Build, Train and Test Model ##\n",
    "## =========================== ##\n",
    "\n",
    "if not PROCESS_LIST_OF_MODELS:\n",
    "    print('Not configured for list of models')\n",
    "else:\n",
    "    model_metrics_list = build_and_train_model_list(model_list=MODEL_LIST,\n",
    "                    run_training=RUN_TRAINING,\n",
    "                    total_training_epochs=TRAINING_EPOCHS,\n",
    "                    validation_data=validation_data,\n",
    "                    test_data=test_data,\n",
    "                    export_model=EXPORT_MODEL,\n",
    "                    output_dir=OUTPUT_DIR,\n",
    "                    run_test=RUN_TEST,\n",
    "                    num_test_images=NUM_TEST_IMAGES)\n",
    "\n",
    "#     print(model_metrics_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51c51a04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflite_model_maker_env",
   "language": "python",
   "name": "tflite_model_maker_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
